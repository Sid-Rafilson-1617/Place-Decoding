{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the paths to olfactory bulb data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of OB sessions with tracking data:  34\n",
      "\n",
      "Number of OB sessions with tracking and sniffing data:  34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_root = r\"E:\\place_decoding\\data\"\n",
    "ob_dir = 'bulb'\n",
    "\n",
    "# Paths to olfactory bulb data:\n",
    "ob_paths = []\n",
    "ob_paths_sniffing = []\n",
    "mouse_ids = os.listdir(os.path.join(path_root, ob_dir))\n",
    "mouse_ids = [mouse_id for mouse_id in mouse_ids if mouse_id.isnumeric()]\n",
    "for mouse_id in mouse_ids:\n",
    "    session_ids = os.listdir(os.path.join(path_root, ob_dir, mouse_id))\n",
    "    for session_id in session_ids:\n",
    "        session_path = os.path.join(path_root, ob_dir, mouse_id, session_id)\n",
    "        files = os.listdir(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files:\n",
    "            ob_paths.append(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files and 'sniff_params' in files:\n",
    "            ob_paths_sniffing.append(session_path)\n",
    "\n",
    "print('\\nNumber of OB sessions with tracking data: ', len(ob_paths))\n",
    "print('\\nNumber of OB sessions with tracking and sniffing data: ', len(ob_paths_sniffing))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the paths to hippocampal data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = r\"E:\\place_decoding\\data\"\n",
    "hipp_dir = 'hipp'\n",
    "            \n",
    "            \n",
    "# Paths to hippocampus data:\n",
    "hipp_paths = []\n",
    "hipp_paths_sniffing = []\n",
    "mouse_ids = os.listdir(os.path.join(path_root, hipp_dir))\n",
    "mouse_ids = [mouse_id for mouse_id in mouse_ids if mouse_id.isnumeric()]\n",
    "for mouse_id in mouse_ids:\n",
    "    session_ids = os.listdir(os.path.join(path_root, hipp_dir, mouse_id))\n",
    "    for session_id in session_ids:\n",
    "        session_path = os.path.join(path_root, hipp_dir, mouse_id, session_id)\n",
    "        files = os.listdir(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files:\n",
    "            hipp_paths.append(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files and 'sniff_params' in files:\n",
    "            hipp_paths_sniffing.append(session_path)\n",
    "\n",
    "print('\\nNumber of hippocampal sessions with tracking data: ', len(hipp_paths))\n",
    "print('\\nNumber of hippocampal sessions with tracking and sniffing data: ', len(hipp_paths_sniffing))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Make plots for all of the olfactory bulb sessions with tracking data.***\n",
    "\n",
    "We ignore the floor flip for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots for all of the olfactory bulb sessions with tracking data. We ignore the floor flip for now.\n",
    "for path in ob_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    _ = preprocess_data(path, bin_size=20, make_plots=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Make plots for all of the hippocampal sessions with tracking data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for path in hipp_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    _ = preprocess_data(path, bin_size=20, make_plots=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum achievable error:  40.824829046386306\n",
      "Chance performance error:  375.27767497325675\n"
     ]
    }
   ],
   "source": [
    "# Number of boxes along each dimension for decoding:\n",
    "nx, ny = 12, 5\n",
    "\n",
    "# The box boundaries for spatial tracking (see readme file):\n",
    "x_min, x_max = 0, 1200\n",
    "y_min, y_max = 0, 500\n",
    "\n",
    "# The minimum and maximum error that we would expect given the size of the bins:\n",
    "dx = (x_max-x_min)/nx\n",
    "dy = (y_max-y_min)/ny\n",
    "err_min = ((dx**2 + dy**2)/12)**0.5\n",
    "err_chance = (((x_max-x_min)**2 + (y_max-y_min)**2)/12)**0.5\n",
    "print('Minimum achievable error: ', err_min)\n",
    "print('Chance performance error: ', err_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[hipp_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Decoding\n",
    "\n",
    "***decoding all the olfactor bulb sessions without considering the floor flip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the spatial decoding with no floor flip for the olfactory bulb data: \n",
    "\n",
    "\n",
    "bin_size = 20  # number of 10ms time steps to include in each bin\n",
    "\n",
    "for path in ob_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    # preprocess the data getting the spike counts and position:\n",
    "    spks, pos, _, _ = preprocess_data(path, bin_size=bin_size)\n",
    "    if spks is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # calculate the decoding error on the 2D grid:\n",
    "    err, _, pos_pred = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                            boundaries=(x_min,x_max,y_min,y_max))\n",
    "    np.save(path + '/decoding_err.npy', err)\n",
    "    np.save(path + '/pos_pred.npy', pos_pred)\n",
    "\n",
    "\n",
    "    # calculate the decoding error with shuffling:\n",
    "    err_shuffle, _, pos_pred_shuffle = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                        boundaries=(x_min,x_max,y_min,y_max), shuffle=True)\n",
    "    np.save(path + '/decoding_err_shuffle.npy', err_shuffle)\n",
    "    np.save(path + '/pos_pred_shuffle.npy', pos_pred_shuffle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Decoding all the hippocampal sessions without considering the floor flip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do the spatial decoding with no floor flip for the hippocampal data: \n",
    "\n",
    "\n",
    "bin_size = 20  # number of 10ms time steps to include in each bin\n",
    "\n",
    "for path in hipp_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    # preprocess the data getting the spike counts and position:\n",
    "    spks, pos, _, _ = preprocess_data(path, bin_size=bin_size)\n",
    "    if spks is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # calculate the decoding error on the 2D grid:\n",
    "    err, _, pos_pred = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                            boundaries=(x_min,x_max,y_min,y_max))\n",
    "    np.save(path + '/decoding_err.npy', err)\n",
    "    np.save(path + '/pos_pred.npy', pos_pred)\n",
    "\n",
    "\n",
    "    # calculate the decoding error with shuffling:\n",
    "    err_shuffle, _, pos_pred_shuffle = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                        boundaries=(x_min,x_max,y_min,y_max), shuffle=True)\n",
    "    np.save(path + '/decoding_err_shuffle.npy', err_shuffle)\n",
    "    np.save(path + '/pos_pred_shuffle.npy', pos_pred_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Decoding all the olfactory bulb sessions considering the floor flip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the spatial decoding for the olfactory bulb sessions, with floor flip\n",
    "\n",
    "bin_size = 20  # number of 10ms time steps to include in each bin\n",
    "\n",
    "# Define training and testing conditions and shuffle states\n",
    "train_test_conditions = [\n",
    "    ('pre', 'pre'),\n",
    "    ('post', 'post'),\n",
    "    ('pre', 'post'),\n",
    "    ('post', 'pre')\n",
    "]\n",
    "shuffle_states = [False, True]\n",
    "\n",
    "for path in ob_paths:  # Loop through all sessions\n",
    "    print('\\nAnalyzing ' + path)\n",
    "    if 'events.mat' in os.listdir(path):\n",
    "        events = loadmat(path + '/events.mat')['events']\n",
    "        frame_flip1 = events[2, 0]  # Frame at which floor flip begins\n",
    "\n",
    "        if frame_flip1 != 0:  # Only analyze if there's a floor flip\n",
    "\n",
    "            # Preprocess the data\n",
    "            spks_pre, pos_pre, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='pre')\n",
    "            spks_post, pos_post, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='post')\n",
    "\n",
    "            if spks_pre is None or spks_post is None:\n",
    "                continue\n",
    "\n",
    "            for train_on, test_on in train_test_conditions:\n",
    "                for shuffle in shuffle_states:\n",
    "                    shuffle_str = '_shuffle' if shuffle else ''\n",
    "                    train_test_str = f\"train_{train_on}_test_{test_on}{shuffle_str}\"\n",
    "\n",
    "                    print(f'{train_test_str.capitalize()}...')\n",
    "\n",
    "                    err, ent, pos_pred = decoding_err_floorflip(\n",
    "                        pos_pre, pos_post, spks_pre, spks_post, \n",
    "                        n_squares=(nx, ny), boundaries=(x_min, x_max, y_min, y_max), \n",
    "                        kCV=10, shuffle=shuffle, train_on=train_on, test_on=test_on\n",
    "                    )\n",
    "                    \n",
    "                    # Save results\n",
    "                    np.save(path + f'/decoding_err_{train_test_str}.npy', err)\n",
    "                    np.save(path + f'/pos_pred_{train_test_str}.npy', pos_pred)\n",
    "\n",
    "        else:\n",
    "            print('No floor flip, skipping session...')\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print('No events file, skipping session...')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding all the OB floor flip but with 180 degree rotated fictive values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing E:\\place_decoding\\data\\bulb\\4122\\4\n",
      "No floor flip, skipping session...\n",
      "\n",
      "Analyzing E:\\place_decoding\\data\\bulb\\4122\\5\n",
      "No floor flip, skipping session...\n",
      "\n",
      "Analyzing E:\\place_decoding\\data\\bulb\\4122\\6\n",
      "No floor flip, skipping session...\n",
      "\n",
      "Analyzing E:\\place_decoding\\data\\bulb\\4127\\10\n",
      "No floor flip, skipping session...\n",
      "\n",
      "Analyzing E:\\place_decoding\\data\\bulb\\4127\\12\n",
      "Mask is small or empty after applying floor flip conditions.\n",
      "\n",
      "Analyzing E:\\place_decoding\\data\\bulb\\4127\\14\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_on' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shuffle \u001b[38;5;129;01min\u001b[39;00m shuffle_states:\n\u001b[0;32m     21\u001b[0m     shuffle_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_shuffle\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 22\u001b[0m     train_test_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtrain_on\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_on\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mshuffle_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_test_str\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m     err, ent, pos_pred \u001b[38;5;241m=\u001b[39m decoding_err_floorflip(\n\u001b[0;32m     27\u001b[0m         pos_pre, pos_post, spks_pre, spks_post, \n\u001b[0;32m     28\u001b[0m         n_squares\u001b[38;5;241m=\u001b[39m(nx, ny), boundaries\u001b[38;5;241m=\u001b[39m(x_min, x_max, y_min, y_max), \n\u001b[0;32m     29\u001b[0m         kCV\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39mshuffle, train_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, test_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m, rotate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_on' is not defined"
     ]
    }
   ],
   "source": [
    "bin_size = 20\n",
    "\n",
    "shuffle_states = [False, True]\n",
    "\n",
    "for path in ob_paths:  # Loop through all sessions\n",
    "    print('\\nAnalyzing ' + path)\n",
    "    if 'events.mat' in os.listdir(path):\n",
    "        events = loadmat(path + '/events.mat')['events']\n",
    "        frame_flip1 = events[2, 0]  # Frame at which floor flip begins\n",
    "\n",
    "        if frame_flip1 != 0:  # Only analyze if there's a floor flip\n",
    "\n",
    "            # Preprocess the data\n",
    "            spks_pre, pos_pre, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='pre')\n",
    "            spks_post, pos_post, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='post')\n",
    "\n",
    "            if spks_pre is None or spks_post is None:\n",
    "                continue\n",
    "\n",
    "            for shuffle in shuffle_states:\n",
    "                shuffle_str = '_shuffle' if shuffle else ''\n",
    "                train_test_str = f\"train_post_test_pre{shuffle_str}\"\n",
    "\n",
    "                print(f'{train_test_str.capitalize()}...')\n",
    "\n",
    "                err, ent, pos_pred = decoding_err_floorflip(\n",
    "                    pos_pre, pos_post, spks_pre, spks_post, \n",
    "                    n_squares=(nx, ny), boundaries=(x_min, x_max, y_min, y_max), \n",
    "                    kCV=10, shuffle=shuffle, train_on='post', test_on='pre', rotate = True\n",
    "                )\n",
    "                \n",
    "                if shuffle:\n",
    "                    np.save(path + f'/decoding_err_train_post_test_prerotated_shuffle.npy', err)\n",
    "                    np.save(path + f'/pos_pred_train_post_test_prerotated_shuffle.npy', pos_pred)\n",
    "                else:\n",
    "                    np.save(path + f'/decoding_err_train_post_test_prerotated.npy', err)\n",
    "                    np.save(path + f'/pos_pred_train_post_test_prerotated.npy', pos_pred)\n",
    "\n",
    "        else:\n",
    "            print('No floor flip, skipping session...')\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print('No events file, skipping session...')\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

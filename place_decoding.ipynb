{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the paths to olfactory bulb data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_root = r\"E:\\place_decoding\\data\"\n",
    "ob_dir = 'bulb'\n",
    "\n",
    "# Paths to olfactory bulb data:\n",
    "ob_paths = []\n",
    "ob_paths_sniffing = []\n",
    "mouse_ids = os.listdir(os.path.join(path_root, ob_dir))\n",
    "for mouse_id in mouse_ids:\n",
    "    session_ids = os.listdir(os.path.join(path_root, ob_dir, mouse_id))\n",
    "    for session_id in session_ids:\n",
    "        session_path = os.path.join(path_root, ob_dir, mouse_id, session_id)\n",
    "        files = os.listdir(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files:\n",
    "            ob_paths.append(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files and 'sniff_params' in files:\n",
    "            ob_paths_sniffing.append(session_path)\n",
    "\n",
    "print('\\nNumber of OB sessions with tracking data: ', len(ob_paths))\n",
    "print('\\nNumber of OB sessions with tracking and sniffing data: ', len(ob_paths_sniffing))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the paths to hippocampal data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of hippocampal sessions with tracking data:  16\n",
      "\n",
      "Number of hippocampal sessions with tracking and sniffing data:  16\n"
     ]
    }
   ],
   "source": [
    "path_root = r\"E:\\place_decoding\\data\"\n",
    "hipp_dir = 'hipp'\n",
    "            \n",
    "            \n",
    "# Paths to hippocampus data:\n",
    "hipp_paths = []\n",
    "hipp_paths_sniffing = []\n",
    "mouse_ids = os.listdir(os.path.join(path_root, hipp_dir))\n",
    "for mouse_id in mouse_ids:\n",
    "    session_ids = os.listdir(os.path.join(path_root, hipp_dir, mouse_id))\n",
    "    for session_id in session_ids:\n",
    "        session_path = os.path.join(path_root, hipp_dir, mouse_id, session_id)\n",
    "        files = os.listdir(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files:\n",
    "            hipp_paths.append(session_path)\n",
    "        if 'track.mat' or 'mtracks.mat' in files and 'sniff_params' in files:\n",
    "            hipp_paths_sniffing.append(session_path)\n",
    "\n",
    "print('\\nNumber of hippocampal sessions with tracking data: ', len(hipp_paths))\n",
    "print('\\nNumber of hippocampal sessions with tracking and sniffing data: ', len(hipp_paths_sniffing))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Make plots for all of the olfactory bulb sessions with tracking data.***\n",
    "\n",
    "We ignore the floor flip for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots for all of the olfactory bulb sessions with tracking data. We ignore the floor flip for now.\n",
    "for path in ob_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    _ = preprocess_data(path, bin_size=20, make_plots=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Make plots for all of the hippocampal sessions with tracking data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for path in hipp_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    _ = preprocess_data(path, bin_size=20, make_plots=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum achievable error:  40.824829046386306\n",
      "Chance performance error:  375.27767497325675\n"
     ]
    }
   ],
   "source": [
    "# Number of boxes along each dimension for decoding:\n",
    "nx, ny = 12, 5\n",
    "\n",
    "# The box boundaries for spatial tracking (see readme file):\n",
    "x_min, x_max = 0, 1200\n",
    "y_min, y_max = 0, 500\n",
    "\n",
    "# The minimum and maximum error that we would expect given the size of the bins:\n",
    "dx = (x_max-x_min)/nx\n",
    "dy = (y_max-y_min)/ny\n",
    "err_min = ((dx**2 + dy**2)/12)**0.5\n",
    "err_chance = (((x_max-x_min)**2 + (y_max-y_min)**2)/12)**0.5\n",
    "print('Minimum achievable error: ', err_min)\n",
    "print('Chance performance error: ', err_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['E:\\\\place_decoding\\\\data\\\\hipp\\\\4132\\\\3',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4132\\\\4',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4132\\\\5',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4132\\\\6',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4133\\\\1',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4133\\\\2',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4133\\\\4',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4133\\\\5',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4134\\\\2',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4134\\\\3',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4134\\\\4',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4135\\\\1',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4135\\\\2',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4137\\\\1',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4137\\\\2',\n",
       "  'E:\\\\place_decoding\\\\data\\\\hipp\\\\4137\\\\3']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[hipp_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Decoding\n",
    "\n",
    "***decoding all the olfactor bulb sessions without considering the floor flip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the spatial decoding with no floor flip for the olfactory bulb data: \n",
    "\n",
    "\n",
    "bin_size = 20  # number of 10ms time steps to include in each bin\n",
    "\n",
    "for path in ob_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    # preprocess the data getting the spike counts and position:\n",
    "    spks, pos, _, _ = preprocess_data(path, bin_size=bin_size)\n",
    "    if spks is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # calculate the decoding error on the 2D grid:\n",
    "    err, _, pos_pred = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                            boundaries=(x_min,x_max,y_min,y_max))\n",
    "    np.save(path + '/decoding_err.npy', err)\n",
    "    np.save(path + '/pos_pred.npy', pos_pred)\n",
    "\n",
    "\n",
    "    # calculate the decoding error with shuffling:\n",
    "    err_shuffle, _, pos_pred_shuffle = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                        boundaries=(x_min,x_max,y_min,y_max), shuffle=True)\n",
    "    np.save(path + '/decoding_err_shuffle.npy', err_shuffle)\n",
    "    np.save(path + '/pos_pred_shuffle.npy', pos_pred_shuffle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Decoding all the hippocampal sessions without considering the floor flip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing E:\\place_decoding\\data\\hipp\\4132\\3\n",
      "n_neurons:  39\n",
      "Spatial decoding error:  303.85406013656586 +/- 42.72103020391384\n",
      "n_neurons:  39\n",
      "Spatial decoding error:  288.38272565104927 +/- 42.06961172151979\n",
      "Analyzing E:\\place_decoding\\data\\hipp\\4132\\4\n",
      "n_neurons:  90\n",
      "Spatial decoding error:  241.77316882351755 +/- 23.53583081790263\n",
      "n_neurons:  90\n",
      "Spatial decoding error:  302.84896612615046 +/- 31.29305382042325\n",
      "Analyzing E:\\place_decoding\\data\\hipp\\4132\\5\n",
      "n_neurons:  57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Do the spatial decoding with no floor flip for the hippocampal data: \n",
    "\n",
    "\n",
    "bin_size = 20  # number of 10ms time steps to include in each bin\n",
    "\n",
    "for path in hipp_paths:\n",
    "    print('Analyzing ' + path)\n",
    "\n",
    "    # preprocess the data getting the spike counts and position:\n",
    "    spks, pos, _, _ = preprocess_data(path, bin_size=bin_size)\n",
    "    if spks is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # calculate the decoding error on the 2D grid:\n",
    "    err, _, pos_pred = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                            boundaries=(x_min,x_max,y_min,y_max))\n",
    "    np.save(path + '/decoding_err.npy', err)\n",
    "    np.save(path + '/pos_pred.npy', pos_pred)\n",
    "\n",
    "\n",
    "    # calculate the decoding error with shuffling:\n",
    "    err_shuffle, _, pos_pred_shuffle = decoding_err_multithreadCV(pos, spks, n_squares=(nx,ny), \n",
    "                        boundaries=(x_min,x_max,y_min,y_max), shuffle=True)\n",
    "    np.save(path + '/decoding_err_shuffle.npy', err_shuffle)\n",
    "    np.save(path + '/pos_pred_shuffle.npy', pos_pred_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Decoding all the olfactory bulb sessions considering the floor flip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the spatial decoding for the olfactory bulb sessions, with floor flip\n",
    "\n",
    "bin_size = 20  # number of 10ms time steps to include in each bin\n",
    "\n",
    "# Define training and testing conditions and shuffle states\n",
    "train_test_conditions = [\n",
    "    ('pre', 'pre'),\n",
    "    ('post', 'post'),\n",
    "    ('pre', 'post'),\n",
    "    ('post', 'pre')\n",
    "]\n",
    "shuffle_states = [False, True]\n",
    "\n",
    "for path in ob_paths:  # Loop through all sessions\n",
    "    if 'events.mat' in os.listdir(path):\n",
    "        events = loadmat(path + '/events.mat')['events']\n",
    "        frame_flip1 = events[2, 0]  # Frame at which floor flip begins\n",
    "\n",
    "        if frame_flip1 != 0:  # Only analyze if there's a floor flip\n",
    "\n",
    "            # Preprocess the data\n",
    "            spks_pre, pos_pre, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='pre')\n",
    "            spks_post, pos_post, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='post')\n",
    "\n",
    "            for train_on, test_on in train_test_conditions:\n",
    "                for shuffle in shuffle_states:\n",
    "                    shuffle_str = '_shuffle' if shuffle else ''\n",
    "                    train_test_str = f\"train_{train_on}_test_{test_on}{shuffle_str}\"\n",
    "\n",
    "                    print(f'{train_test_str.capitalize()}...')\n",
    "\n",
    "                    err, ent, pos_pred = decoding_err_floorflip(\n",
    "                        pos_pre, pos_post, spks_pre, spks_post, \n",
    "                        n_squares=(nx, ny), boundaries=(x_min, x_max, y_min, y_max), \n",
    "                        kCV=10, shuffle=shuffle, train_on=train_on, test_on=test_on\n",
    "                    )\n",
    "                    \n",
    "                    # Save results\n",
    "                    np.save(path + f'/decoding_err_{train_test_str}.npy', err)\n",
    "                    np.save(path + f'/pos_pred_{train_test_str}.npy', pos_pred)\n",
    "\n",
    "        else:\n",
    "            print('No floor flip, skipping session...')\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print('No events file, skipping session...')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Decoding all the hippocampal sessions considering the floor flip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 20  # number of 10ms time steps to include in each bin\n",
    "\n",
    "# Define training and testing conditions and shuffle states\n",
    "train_test_conditions = [\n",
    "    ('pre', 'pre'),\n",
    "    ('post', 'post'),\n",
    "    ('pre', 'post'),\n",
    "    ('post', 'pre')\n",
    "]\n",
    "shuffle_states = [False, True]\n",
    "\n",
    "for path in hipp_paths:  # Loop through all sessions\n",
    "    if 'events.mat' in os.listdir(path):\n",
    "        events = loadmat(path + '/events.mat')['events']\n",
    "        frame_flip1 = events[2, 0]  # Frame at which floor flip begins\n",
    "\n",
    "        if frame_flip1 != 0:  # Only analyze if there's a floor flip\n",
    "\n",
    "            # Preprocess the data\n",
    "            spks_pre, pos_pre, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='pre')\n",
    "            spks_post, pos_post, _, _ = preprocess_data(path, bin_size=bin_size, flip_data='post')\n",
    "\n",
    "            for train_on, test_on in train_test_conditions:\n",
    "                for shuffle in shuffle_states:\n",
    "                    shuffle_str = '_shuffle' if shuffle else ''\n",
    "                    train_test_str = f\"train_{train_on}_test_{test_on}{shuffle_str}\"\n",
    "\n",
    "                    print(f'{train_test_str.capitalize()}...')\n",
    "\n",
    "                    err, ent, pos_pred = decoding_err_floorflip(\n",
    "                        pos_pre, pos_post, spks_pre, spks_post, \n",
    "                        n_squares=(nx, ny), boundaries=(x_min, x_max, y_min, y_max), \n",
    "                        kCV=10, shuffle=shuffle, train_on=train_on, test_on=test_on\n",
    "                    )\n",
    "                    \n",
    "                    # Save results\n",
    "                    np.save(path + f'/decoding_err_{train_test_str}.npy', err)\n",
    "                    np.save(path + f'/pos_pred_{train_test_str}.npy', pos_pred)\n",
    "\n",
    "        else:\n",
    "            print('No floor flip, skipping session...')\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print('No events file, skipping session...')\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
